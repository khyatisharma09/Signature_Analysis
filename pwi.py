# -*- coding: utf-8 -*-
"""PWI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VLlBMQlScw8xyOmBRtTvh_aD3Tjg87C8
"""

import tensorflow as tf

from google.colab import drive
drive.mount('/content/gdrive')

df = tf.keras.preprocessing.image_dataset_from_directory('/content/gdrive/MyDrive/signature_dataset')

ds_train = tf.keras.preprocessing.image_dataset_from_directory('/content/gdrive/MyDrive/signature_dataset',validation_split = 0.2,subset = 'training',seed = 123)

ds_validation = tf.keras.preprocessing.image_dataset_from_directory('/content/gdrive/MyDrive/signature_dataset', validation_split=0.2, subset = 'validation' , seed = 123)

#define batch size and print image labels
# import tensorflow_datasets as tfds

batch_size = 64

dataset_name = df
class_names = df.class_names
print(class_names)

val_batch = tf.data.experimental.cardinality(ds_validation)
# test_dataset = ds_validation.take(val_batch // 5)
validation_dataset = ds_validation.skip(val_batch // 5)

#resize images and standardize data to make it for nn:
size = (512,512)
ds_train = ds_train.map(lambda image, label : (tf.image.resize(image,size),label))
ds_validation = ds_validation.map(lambda image, label: (tf.image.resize(image,size), label))
# ds_test = test_dataset.map(lambda image, label : (tf.image.resize(image,size), label))

import matplotlib.pyplot as plt
plt.figure(figsize = (10,10))
for images, labels in ds_train.take(1):
  for i in range(9):
    ax = plt.subplot(3,3,i+1)
    plt.imshow(images[i].numpy().astype('uint8'))
    plt.title(class_names[labels[i]])
    plt.axis("off")

#further preprocessing to increase instance of image to improve accuracy from various viewpoints

from tensorflow.keras.models import Sequential
from tensorflow.keras import layers

image = Sequential(
    [
        layers.RandomFlip('horizontal'),
        layers.RandomRotation(0.1),
        layers.RandomZoom(height_factor=(-0.2,-0.3), width_factor = (-0.2,-0.3), interpolation = 'bilinear'),
        layers.RandomContrast(factor = 0.1),
        layers.RandomTranslation(height_factor = 0.1, width_factor = 0.1),
    ],
    name = 'image',
)

import numpy as np

for images, labels in ds_train.take(1):
  plt.figure(figsize = (10,10))
  first_image = images[0]
  def f(x):
    return np.int(x)
  f2 = np.vectorize(f)
  for i in range(9):
    ax = plt.subplot(3,3,i+1)
    augmented_image = image(
        tf.expand_dims(first_image, 0), training = True
    )
    plt.imshow(augmented_image[0].numpy().astype('int32'))
    plt.title(f2(labels[0]))
    plt.axis("off")

NUM_CLASSES = len(class_names)
print(NUM_CLASSES)

!pip install tensorflow-addons

import tensorflow_addons as tfa

#one-hot encoding for categorical dataset:
def input_preprocess(image, label):
  label = tf.one_hot(label,NUM_CLASSES)
  return image, label

ds_train = ds_train.map(input_preprocess,num_parallel_calls=tf.data.AUTOTUNE)
ds_train = ds_train.prefetch(tf.data.AUTOTUNE)
# ds_test = ds_test.map(input_preprocess)
# ds_test = ds_test.prefetch(tf.data.AUTOTUNE)
ds_validation = ds_validation.map(input_preprocess)
ds_validation = ds_validation.prefetch(tf.data.AUTOTUNE)

model  = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32,(3,3) , activation = 'relu' , input_shape = (512,512 ,3)),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(64,(3,3) , activation = 'relu'),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128,activation = 'relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(4, activation = 'softmax')
])

model.compile(
    optimizer = 'adam' , loss = "categorical_crossentropy", metrics=["accuracy", tf.keras.metrics.Recall(name='recall'),
    tf.keras.metrics.Precision(name='precision'), tfa.metrics.F1Score(name='f1_score', num_classes = 4),
    ]
)

model.summary()

from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping
es = EarlyStopping(monitor = 'val_accuracy' , min_delta = 0.01 , patience=10, verbose=1)

model_cp = ModelCheckpoint(filepath="/content/gdrive/MyDrive/Weights/myCNN_modelv1.H5" , monitor = "val_accuracy",
                           save_best_only = True,
                           save_weights_only = False,
                           verbose =1)

epochs = 10
hist = model.fit(ds_train, epochs = epochs, validation_data = ds_validation, callbacks = [model_cp ,es], batch_size = 64, verbose = 1)

import matplotlib.pyplot as plt

def plot_hist(hist):
  plt.plot(hist.
  history['accuracy'])
  plt.plot(hist.history['val_accuracy'])
  plt.title('Model Accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'validation'] , loc = "upper left")
  plt.show()

plot_hist(hist)

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

saved_model_path = "/content/gdrive/MyDrive/Weights/myCNN_modelv1.H5"
loaded_model = tf.keras.models.load_model(saved_model_path)

def predict_image(image_path, loaded_model, class_names):
    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(512, 512))
    input_arr = tf.keras.preprocessing.image.img_to_array(image)
    input_arr = np.array([input_arr])  # Convert single image to a batch.
    predictions = loaded_model.predict(input_arr)
    predicted_label = class_names[np.argmax(predictions)]
    return predicted_label

# Specify the image path for testing
image_path = "/content/gdrive/MyDrive/test_dataset/TEST_DATA/09201092.png"

predicted_label = predict_image(image_path, loaded_model, class_names)
print(f"Predicted label: {predicted_label}")

image = plt.imread(image_path)
plt.imshow(image)
plt.title(f"Predicted: {predicted_label}")
plt.show()

